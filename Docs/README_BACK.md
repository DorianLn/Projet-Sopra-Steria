# ğŸ“š Backend â€“ Analyse et GÃ©nÃ©ration Automatique de CV

## ğŸ“‹ Description

Ce backend a Ã©tÃ© dÃ©veloppÃ© dans le cadre d'un projet Ã©tudiant en partenariat avec **Sopra Steria**.  
Son objectif est d'automatiser le traitement de CV non structurÃ©s (PDF ou DOCX) afin de :

- simplifier l'analyse des informations d'un candidat,
- standardiser la prÃ©sentation de ces donnÃ©es,
- gÃ©nÃ©rer automatiquement des documents professionnels (DOCX & PDF),
- tout en respectant les contraintes de **confidentialitÃ©** (traitement 100% local).

L'application analyse un CV grÃ¢ce Ã  un **pipeline robuste** mÃªlant expressions rÃ©guliÃ¨res, NLP (spaCy), classification heuristique et fuzzy matching.

---

## âœ¨ FonctionnalitÃ©s

### âœ” FonctionnalitÃ©s principales (implÃ©mentÃ©es)

- âœ… Import de CV **PDF** ou **DOCX**
- âœ… Extraction d'informations complÃ¨tes :
  - **Contact** : Nom, email, tÃ©lÃ©phone, adresse postale, LinkedIn, GitHub
  - **ExpÃ©riences** : Titre, entreprise, dates, description, technos
  - **Formations** : DiplÃ´me, Ã©cole, dates, niveau
  - **CompÃ©tences** : Techniques, mÃ©tiers, outils, langages
  - **Certifications** : Nom, organisme, date
  - **Langues** : Langue, niveau
  - **Projets** : Titre, description, technologies
- âœ… Analyse NLP via **spaCy** (NER + classification texte)
- âœ… RÃ¨gles heuristiques intelligentes pour segmentation
- âœ… Fuzzy matching pour normalisation des donnÃ©es
- âœ… Export automatique en **JSON structurÃ©**
- âœ… API RESTful complÃ¨te
- âœ… Gestion des fichiers temporaires
- âœ… Traitement **100% local** (aucune API externe)

### ğŸ“‹ FonctionnalitÃ©s futures (Ã  implÃ©menter)

- [ ] GÃ©nÃ©ration automatique DOCX (template Sopra)
- [ ] Conversion DOCX â†’ PDF (branding Sopra Steria)
- [ ] Conversion PDF d'entrÃ©e â†’ DOCX

---

## ğŸ› ï¸ Technologies

| Domaine | Outils |
|---------|--------|
| **Framework** | Flask, Flask-CORS |
| **Extraction** | Regex, spaCy (fr_core_news_md) |
| **Manipulation docs** | python-docx, docxtpl, PyPDF2 |
| **Conversion** | docx2pdf, win32com |
| **NLP avancÃ©** | rapidfuzz, dateparser |
| **GÃ©nÃ©ration PDF** | ReportLab |
| **Tests** | pytest |

---

## ğŸ“‚ Architecture

```
backend/
â”‚
â”œâ”€â”€ api.py                       # Point d'entrÃ©e API Flask
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”‚
â”œâ”€â”€ extractors/                  # ğŸ” Modules d'extraction
â”‚   â”œâ”€â”€ robust_extractor.py      # Pipeline d'extraction PRINCIPAL
â”‚   â”œâ”€â”€ spacy_extractor.py       # NER spaCy + classification
â”‚   â”œâ”€â”€ enhanced_extractor.py    # Extraction regex avancÃ©e
â”‚   â”œâ”€â”€ heuristic_rules.py       # RÃ¨gles heuristiques
â”‚   â”œâ”€â”€ section_classifier.py    # Classification sections
â”‚   â”œâ”€â”€ version_mapper.py        # Conversion formats de donnÃ©es
â”‚   â””â”€â”€ config.py                # Configuration centralisÃ©e
â”‚
â”œâ”€â”€ generators/                  # ğŸ“ GÃ©nÃ©ration documents
â”‚   â”œâ”€â”€ generate_sopra_docx.py   # DOCX standardisÃ©
â”‚   â””â”€â”€ docx_to_pdf.py           # Conversion DOCX â†’ PDF
â”‚
â”œâ”€â”€ models/                      # ğŸ§  ModÃ¨les spaCy
â”‚   â”œâ”€â”€ cv_ner/                  # ModÃ¨le NER personnalisÃ©
â”‚   â””â”€â”€ cv_pipeline/             # Pipeline complet
â”‚
â”œâ”€â”€ training/                    # ğŸ“ Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ train_ner.py
â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”œâ”€â”€ train_textcat.py
â”‚   â”œâ”€â”€ generate_training_data.py
â”‚   â””â”€â”€ training_data.py
â”‚
â”œâ”€â”€ templates/                   # ğŸ“‹ Templates DOCX
â”‚   â””â”€â”€ sopra_template.docx
â”‚
â”œâ”€â”€ data/                        # ğŸ“Š DonnÃ©es
â”‚   â”œâ”€â”€ input/                   # CV uploadÃ©s
â”‚   â””â”€â”€ output/                  # JSON gÃ©nÃ©rÃ©s
â”‚
â””â”€â”€ test_*.py                    # ğŸ§ª Tests
    â”œâ”€â”€ test_integration.py
    â”œâ”€â”€ test_cv.py
    â”œâ”€â”€ test_nom_prenom.py
    â”œâ”€â”€ test_cas_rue.py
    â””â”€â”€ ...
```

---

## ğŸš€ Installation & Configuration

### 1. Cloner le projet

```bash
git clone https://github.com/DorianLn/Projet-Sopra-Steria.git
cd Projet-Sopra-Steria/backend
```

### 2. CrÃ©er l'environnement Python

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS / Linux
source venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Installer le modÃ¨le spaCy franÃ§ais

```bash
python -m spacy download fr_core_news_md
```

### 5. Lancer le serveur API

```bash
python api.py
```

âœ… L'API dÃ©marre sur **http://localhost:5000**

---

## ğŸ”Œ Endpoints API

### 1ï¸âƒ£ Analyser un CV

**`POST /api/cv/analyze`**

**Body** : FormData avec le fichier

```bash
curl -X POST -F "file=@mon_cv.pdf" http://localhost:5000/api/cv/analyze
```

**RÃ©ponse :**
```json
{
  "contact": {
    "nom": "Jean Dupont",
    "email": "jean.dupont@email.com",
    "telephone": "+33612345678",
    "adresse": "Paris, France",
    "linkedin": "linkedin.com/in/jeandupont"
  },
  "experiences": [
    {
      "titre": "DÃ©veloppeur Senior",
      "entreprise": "Tech Corp",
      "date_debut": "2020-01",
      "date_fin": "PrÃ©sent",
      "description": "DÃ©veloppement backend...",
      "technologies": ["Python", "Flask", "PostgreSQL"]
    }
  ],
  "formations": [
    {
      "diplome": "Master Informatique",
      "ecole": "UniversitÃ© Paris Tech",
      "date_fin": "2019",
      "specialisation": "Intelligence Artificielle"
    }
  ],
  "competences": ["Python", "JavaScript", "Machine Learning"],
  "langues": [
    {
      "langue": "FranÃ§ais",
      "niveau": "Natif"
    }
  ],
  "json_filename": "CV_Jean_Dupont.json"
}
```

### 2ï¸âƒ£ TÃ©lÃ©charger le JSON

**`GET /api/cv/json/<filename>`**

RÃ©cupÃ¨re le fichier JSON structurÃ© gÃ©nÃ©rÃ© lors de l'analyse

### 3ï¸âƒ£ GÃ©nÃ©rer DOCX depuis JSON

**`POST /api/cv/generate-docx`**

GÃ©nÃ¨re un DOCX structurÃ© au format Sopra Steria Ã  partir du JSON extrait

### 4ï¸âƒ£ Convertir DOCX â†’ PDF

**`POST /api/cv/convert-docx-to-pdf`**

Convertit un DOCX gÃ©nÃ©rÃ© en PDF avec branding Sopra Steria

---

## ğŸ§  Pipeline d'extraction

```
Input CV (PDF/DOCX)
    â†“
Extraction texte brut
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ROBUST EXTRACTOR (Pipeline Principal) â”‚
â”‚                                         â”‚
â”‚  1ï¸âƒ£ REGEX EXTRACTION                    â”‚
â”‚     â€¢ Emails, tÃ©lÃ©phones, URLs          â”‚
â”‚     â€¢ Dates (multiples formats)         â”‚
â”‚     â€¢ Adresses postales                 â”‚
â”‚                                         â”‚
â”‚  2ï¸âƒ£ SPACY NER                           â”‚
â”‚     â€¢ Noms, prÃ©noms                     â”‚
â”‚     â€¢ Organisations (entreprises)       â”‚
â”‚     â€¢ LocalitÃ©s                         â”‚
â”‚                                         â”‚
â”‚  3ï¸âƒ£ HEURISTIC RULES                     â”‚
â”‚     â€¢ Segmentation sections             â”‚
â”‚     â€¢ DÃ©tection formations/expÃ©riences  â”‚
â”‚     â€¢ Normalisation contexte            â”‚
â”‚                                         â”‚
â”‚  4ï¸âƒ£ FUZZY MATCHING                      â”‚
â”‚     â€¢ Rapprochement donnÃ©es             â”‚
â”‚     â€¢ Suppression doublons              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
JSON StructurÃ© validÃ©
    â†“
Stockage JSON (data/output)
```

---

## ğŸ“‹ Structure des donnÃ©es (JSON output)

```json
{
  "contact": {
    "nom": "string",
    "email": "string",
    "telephone": "string",
    "adresse": "string",
    "linkedin": "string",
    "github": "string"
  },
  "experiences": [
    {
      "titre": "string",
      "entreprise": "string",
      "date_debut": "YYYY-MM",
      "date_fin": "YYYY-MM ou 'PrÃ©sent'",
      "description": "string",
      "technologies": ["string"]
    }
  ],
  "formations": [
    {
      "diplome": "string",
      "ecole": "string",
      "date_fin": "YYYY-MM",
      "specialisation": "string",
      "niveau": "string"
    }
  ],
  "competences": ["string"],
  "langues": [
    {
      "langue": "string",
      "niveau": "string (Natif, Courant, IntermÃ©diaire, Basique)"
    }
  ]
}
```

---

## ğŸ§ª Tests

```bash
cd backend

# Tous les tests
pytest -v

# Avec couverture
pytest --cov=. --cov-report=html

# Tests spÃ©cifiques
pytest test_integration.py -v
pytest test_nom_prenom.py -v
pytest test_cv.py -v
pytest test_cas_rue.py -v
```

---

## ğŸ”„ RÃ©entraÃ®ner les modÃ¨les

Les modÃ¨les spaCy personnalisÃ©s sont dans `models/cv_ner/` et `models/cv_pipeline/`.

```bash
cd backend

# RÃ©entraÃ®ner le NER
python training/train_ner.py

# RÃ©entraÃ®ner le pipeline
python training/train_pipeline.py

# GÃ©nÃ©rer les donnÃ©es d'entraÃ®nement
python training/generate_training_data.py
```

---

## ğŸš€ AmÃ©liorations futures

- [ ] OCR pour PDF scannÃ©s
- [ ] Support multilingue (EN, ES, DE)
- [ ] API documentation Swagger/OpenAPI
- [ ] Authentification et historique utilisateur
- [ ] Templates DOCX personnalisables
- [ ] Export JSON schema validation
- [ ] Cache et optimisation performance
- [ ] Webhooks pour intÃ©grations

---

## ğŸ‘¥ Contributeurs

- Safae Berrichi
- Dorian Lo Negro
- Thomas Gaugeais
- Julien Thepaut
- Nehade El Mokhtari
- ClÃ©ment

---

## ğŸ“œ Licence

Projet rÃ©alisÃ© dans le cadre d'un partenariat pÃ©dagogique avec **Sopra Steria**.  
Tous droits rÃ©servÃ©s.
