# Fonctionnement du Projet d'Extraction de CV

Ce document d√©taille le fonctionnement technique du syst√®me d'extraction d'informations √† partir de CV.

## 1. Architecture du Projet

```
Projet-Sopra-Steria/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ api.py                    # Point d'entr√©e API Flask
‚îÇ   ‚îú‚îÄ‚îÄ analyser_cv.py            # Script hors-ligne pour tests
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ extractors/               # üîç Extraction
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ robust_extractor.py   # Pipeline principal
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spacy_extractor.py    # NER avec spaCy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ enhanced_extractor.py # Regex avanc√©e
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ heuristic_rules.py    # R√®gles intelligentes
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ section_classifier.py # Classification sections
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ version_mapper.py     # Conversion formats
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.py             # Configuration
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ generators/               # üìù G√©n√©ration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_sopra_docx.py # DOCX
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ docx_to_pdf.py        # Conversion DOCX‚ÜíPDF
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ models/                   # üß† Mod√®les spaCy
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cv_ner/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cv_pipeline/
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ training/                 # üéì Entra√Ænement
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_ner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_pipeline.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ training_data.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ input/                # CVs upload√©s
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ output/               # JSON g√©n√©r√©s
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py                 # Tests
‚îÇ
‚îú‚îÄ‚îÄ frontend/                     # Interface React
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ styles/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ Docs/                         # Documentation
    ‚îú‚îÄ‚îÄ README_BACK.md
    ‚îú‚îÄ‚îÄ README_FRONT.md
    ‚îú‚îÄ‚îÄ fonctionnement_du_projet.md
    ‚îú‚îÄ‚îÄ NORMALISATION_CV.md
    ‚îú‚îÄ‚îÄ analyse_back.md
    ‚îî‚îÄ‚îÄ CI.md
```

---

## 2. Flux d'Extraction Complet

### 2.1 √âtape 1 : Upload et R√©ception

```
Frontend                          Backend (api.py)
   ‚îÇ                                ‚îÇ
   ‚îú‚îÄ S√©lection fichier CV          ‚îÇ
   ‚îÇ  (PDF ou DOCX)                 ‚îÇ
   ‚îÇ                                ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  POST /api/cv/analyze
                                    ‚îî‚îÄ Stockage data/input/
```

**Validations** :
- ‚úÖ Format autoris√© : PDF ou DOCX
- ‚úÖ Fichier non vide
- ‚úÖ Pas de doublons simultan√©s

### 2.2 √âtape 2 : Extraction de Texte Brut

```
PDF/DOCX (data/input/)
    ‚Üì
robust_extractor.py
‚îú‚îÄ PDF ‚Üí pdfplumber (extraction texte)
‚îî‚îÄ DOCX ‚Üí python-docx (lecture paragraphes)
    ‚Üì
Texte brut standardis√©
```

### 2.3 √âtape 3 : Pipeline d'Extraction (ROBUST)

Le c≈ìur du syst√®me utilise **4 niveaux d'extraction** :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  NIVEAU 1Ô∏è‚É£ : EXTRACTION REGEX                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Emails : regex@domain.com                     ‚îÇ
‚îÇ ‚Ä¢ T√©l√©phones : +33 6 12 34 56 78                ‚îÇ
‚îÇ ‚Ä¢ URLs : linkedin.com/in/...                    ‚îÇ
‚îÇ ‚Ä¢ Dates : MM/YYYY, YYYY-YYYY, Mois YYYY        ‚îÇ
‚îÇ ‚Ä¢ Adresses : rue, code postal, ville           ‚îÇ
‚îÇ ‚Üí G√©r√©es par enhanced_extractor.py              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  NIVEAU 2Ô∏è‚É£ : SPACY NER                           ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Noms personnels (PER)                         ‚îÇ
‚îÇ ‚Ä¢ Organisations/entreprises (ORG)               ‚îÇ
‚îÇ ‚Ä¢ Localit√©s/villes (LOC)                        ‚îÇ
‚îÇ ‚Ä¢ Dates (DATE)                                  ‚îÇ
‚îÇ ‚Üí Mod√®le : fr_core_news_md (spaCy)              ‚îÇ
‚îÇ ‚Üí G√©r√©es par spacy_extractor.py                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  NIVEAU 3Ô∏è‚É£ : R√àGLES HEURISTIQUES                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Segmentation sections (Exp√©riences, Formations)‚îÇ
‚îÇ ‚Ä¢ D√©tection contexte (type d'emploi)            ‚îÇ
‚îÇ ‚Ä¢ Association dates-entreprises                 ‚îÇ
‚îÇ ‚Üí G√©r√©es par heuristic_rules.py                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  NIVEAU 4Ô∏è‚É£ : FUZZY MATCHING                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ ‚Ä¢ Rapprochement donn√©es similaires              ‚îÇ
‚îÇ ‚Ä¢ Suppression doublons intelligente (rapidfuzz) ‚îÇ
‚îÇ ‚Ä¢ Normalisation des noms d'entreprises          ‚îÇ
‚îÇ ‚Üí G√©r√©es par section_classifier.py              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
JSON STRUCTUR√â VALID√â
```

### 2.4 √âtape 4 : Structuration en JSON

```json
{
  "contact": {
    "nom": "Jean Dupont",
    "email": "jean@example.com",
    "telephone": "+33 6 12 34 56 78",
    "adresse": "5 Rue des Remparts, 69001 Lyon",
    "linkedin": "linkedin.com/in/jeandupont",
    "github": "github.com/jeandupont"
  },
  "experiences": [
    {
      "titre": "D√©veloppeur Python",
      "entreprise": "TechCorp",
      "date_debut": "2020-01",
      "date_fin": "2023-12",
      "description": "D√©veloppement de solutions backend...",
      "technologies": ["Python", "Flask", "PostgreSQL"]
    }
  ],
  "formations": [
    {
      "diplome": "Master Informatique",
      "ecole": "Universit√© Paris Tech",
      "date_fin": "2020",
      "specialisation": "IA",
      "niveau": "Bac+5"
    }
  ],
  "competences": ["Python", "JavaScript", "Docker", "Kubernetes"],
  "langues": [
    {
      "langue": "Fran√ßais",
      "niveau": "Natif"
    },
    {
      "langue": "Anglais",
      "niveau": "C1"
    }
  ]
}
```

### 2.5 √âtape 5 : Stockage et Retour API

```
JSON Valid√©
    ‚Üì
Stockage : data/output/CV_[NOM].json
    ‚Üì
R√©ponse API
‚îî‚îÄ Retour JSON au frontend
   ‚îî‚îÄ Affichage et √©dition possible
```

---

## 3. Pipeline Optionnel : G√©n√©ration Documents

Apr√®s extraction (optionnel) :

```
JSON extraits
    ‚Üì
1Ô∏è‚É£ G√âN√âRER DOCX
   ‚îî‚îÄ generate_sopra_docx.py
      ‚îî‚îÄ Formatage template Sopra Steria
         ‚îî‚îÄ data/output/CV_[NOM].docx
    ‚Üì
2Ô∏è‚É£ CONVERTIR EN PDF
   ‚îî‚îÄ docx_to_pdf.py (via docx2pdf)
      ‚îî‚îÄ data/output/CV_[NOM].pdf
```

---

## 4. D√©tail des Modules Cl√©s

### 4.1 robust_extractor.py (Orchestrateur Principal)

```python
def extract_cv_robust(file_path: str) -> Dict:
    """
    Pipeline principal d'extraction
    
    1. Extrait texte brut (PDF ou DOCX)
    2. Applique extraction regex (emails, t√©l√©phones, dates)
    3. Utilise spaCy NER (noms, organisations)
    4. Applique r√®gles heuristiques (segmentation)
    5. Nettoie avec fuzzy matching
    6. Retourne JSON structur√©
    """
```

### 4.2 spacy_extractor.py (NER)

- Mod√®le : `fr_core_news_md`
- Entit√©s d√©tect√©es : PER (personnes), ORG (organisations), LOC (lieux), DATE
- Fallback regex si NER insuffisant

### 4.3 heuristic_rules.py (Segmentation)

- Classification : Formation vs Exp√©rience
- Association : dates ‚Üî entreprises/√©coles
- Contexte : D√©tection type d'emploi, niveau, technos

### 4.4 section_classifier.py (Finalisation)

- Fuzzy matching (rapidfuzz) pour doublons
- Normalisation donn√©es
- Construction JSON final

---

## 5. Gestion des Erreurs

```
‚ùå Fichier invalide    ‚Üí 400 Bad Request
‚ùå Format non support√© ‚Üí 400 Bad Request
‚ùå Extraction √©chou√©e  ‚Üí 500 Internal Server Error
‚ùå JSON corrompu       ‚Üí Logging + tentative recovery
```

---

## 6. Performance et Optimisations

- **Regex compil√©es** : R√©utilis√©es pour rapidit√©
- **spaCy pipeline** : Charg√© une seule fois en m√©moire
- **Fuzzy matching intelligent** : Limit√© aux donn√©es similaires
- **Traitement local** : Aucun appel API externe

---

## 7. Tests Disponibles

```bash
# Tests unitaires
pytest test_nom_prenom.py -v        # Extraction noms
pytest test_cv.py -v                # Pipeline complet
pytest test_cas_rue.py -v           # Cas sp√©ciaux adresses
pytest test_integration.py -v       # Int√©gration compl√®te
```

---

## 8. Extension Future

- **OCR** : Support PDF scann√©s via Tesseract
- **Multilingue** : Mod√®les spaCy anglais, espagnol, allemand
- **Templates personnalis√©s** : DOCX configurables par organisation
- **Webhooks** : Notifications post-analyse
