# Configuration Mistral / Ollama
# Copiez ce fichier en .env et adaptez si nécessaire

# URL du serveur Ollama
OLLAMA_HOST=http://localhost:11434

# Modèle à utiliser
MISTRAL_MODEL=mistral

# Timeout (secondes) pour les appels Ollama
OLLAMA_TIMEOUT=300

# Nombre de tentatives en cas d'erreur
MISTRAL_MAX_RETRIES=3

# Délai entre les tentatives (secondes)
MISTRAL_RETRY_DELAY=2

# Température du modèle (0.0 = déterministe, 1.0 = créatif)
MISTRAL_TEMPERATURE=0.3

# Taille maximum du prompt (caractères)
# Mistral 7B peut gérer environ 32k tokens (~128k caractères)
MAX_PROMPT_SIZE=100000

# Sauvegarde automatique des résultats
AUTO_SAVE_RESULTS=true

# Dossier de sauvegarde des résultats
RESULTS_OUTPUT_DIR=data/output

# Niveau de log
LOG_LEVEL=INFO

# Vérification Ollama au démarrage
CHECK_OLLAMA_ON_STARTUP=true

# Accepter les erreurs Mistral et utiliser le fallback
ALLOW_FALLBACK=true

# Email pour les notifications d'erreur (optionnel)
# ERROR_NOTIFICATION_EMAIL=admin@example.com
